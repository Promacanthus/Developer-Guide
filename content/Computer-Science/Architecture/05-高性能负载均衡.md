---
title: "05 高性能负载均衡"
date: 2020-06-02T17:36:19+08:00
draft: true
---

- [0.1. 负载均衡分类](#01-负载均衡分类)
  - [0.1.1. DNS负载均衡](#011-dns负载均衡)
    - [0.1.1.1. 优点](#0111-优点)
    - [0.1.1.2. 缺点](#0112-缺点)
  - [0.1.2. 硬件负载均衡](#012-硬件负载均衡)
    - [0.1.2.1. 优点](#0121-优点)
    - [0.1.2.2. 缺点](#0122-缺点)
  - [0.1.3. 软件负载均衡](#013-软件负载均衡)
    - [0.1.3.1. 优点](#0131-优点)
    - [0.1.3.2. 缺点](#0132-缺点)
- [0.2. 负载均衡典型架构](#02-负载均衡典型架构)
- [0.3. 负载均衡算法](#03-负载均衡算法)
  - [0.3.1. 轮询](#031-轮询)
  - [0.3.2. 加权轮询](#032-加权轮询)
  - [0.3.3. 负载最低优先](#033-负载最低优先)
  - [0.3.4. 性能最优类](#034-性能最优类)
  - [0.3.5. Hash类](#035-hash类)

单服务器无论如何优化和升级硬件，总会性能天花板，当无法满足业务需求时，就需要设计高性能集群来提升系统整体的处理性能。

高性能集群的本质就是**通过增加更多的服务器来提升系统整体的计算能力**。

> 计算本身的特点：同样的输入数据和逻辑，无论在哪台服务器上执行，都应该得到相同的输出。

高性能集群设计的复杂度主要体现在增加一个**任务分配器**（负载均衡器），以及为任务选择一个合适的**任务分配算法**。

> 任务分配并**不只是考虑计算单元的负载均衡，**不同的任务分配算法目标是不一样的：
>
> - 有的基于负载考虑
> - 有的基于性能（吞吐量、响应时间）考虑
> - 有的基于业务考虑

## 0.1. 负载均衡分类

### 0.1.1. DNS负载均衡

DNS 是最简单也是最常见的负载均衡方式，一般用来实现**地理级别**的均衡。DNS 负载均衡的本质是**DNS 解析同一个域名可以返回不同的 IP 地址**。

#### 0.1.1.1. 优点

- 简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备。
- 就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。

#### 0.1.1.2. 缺点

- 更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。
- 扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。
- 分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。

> 针对 DNS 负载均衡的一些缺点，对于时延和故障敏感的业务，有一些公司自己实现了 `HTTP-DNS` 的功能，也就是使用 HTTP 协议实现一个私有的 DNS 系统。这样的方案和通用的 DNS 优缺点正好相反。

### 0.1.2. 硬件负载均衡

硬件负载均衡是通过单独的硬件设备来实现负载均衡功能，这类设备和路由器、交换机类似，可以理解为一个用于负载均衡的基础网络设备。

目前业界典型的硬件负载均衡设备有两款：`F5` 和 `A10`。

这类设备性能强劲、功能强大，但价格都不便宜，一般只有“土豪”公司才会考虑使用此类设备。普通业务量级的公司一是负担不起，二是业务量没那么大，用这些设备也是浪费。

#### 0.1.2.1. 优点

- 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。
- 性能强大：软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。
- 稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。
- 支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防 DDoS 攻击等安全功能。

#### 0.1.2.2. 缺点

- 价格昂贵：最普通的一台 F5 就是一台“马6”（20万），好一点的就是“Q7”（80万）。
- 扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。

### 0.1.3. 软件负载均衡

软件负载均衡通过负载均衡软件来实现负载均衡功能，常见的有：

- Nginx 是软件的 7 层负载均衡
- LVS 是 Linux 内核的 4 层负载均衡

> 4 层和 7 层的区别就在于**协议**和**灵活性**，Nginx 支持 `HTTP`、`E-mail` 协议；而 LVS 是 4 层负载均衡，和协议无关，几乎所有应用都可以做，例如，聊天、数据库等。

软件和硬件的最主要区别就在于**性能**，**硬件负载均衡性能远远高于软件负载均衡性能**。

- Ngxin 的性能是**万级**，一般的 Linux 服务器上装一个 Nginx 大概能到 **5万/秒**
- LVS 的性能是**十万级**，据说可达到 **80万/秒**
- F5 性能是**百万级**，从 **200万/秒**到 **800万/秒**都有

软件负载均衡的最大优势是便宜，除了使用开源的系统进行负载均衡，如果业务比较特殊，也可能基于开源系统进行定制（例如，Nginx 插件），甚至进行自研。

#### 0.1.3.1. 优点

- 简单：部署、维护简单
- 便宜：只要 Linux 服务器，装上软件即可
- 灵活：4 层和 7 层负载均衡可以根据业务进行选择；也可以根据业务进行比较方便的扩展，例如，可以通过 Nginx 的插件来实现业务的定制化功能。

#### 0.1.3.2. 缺点

与硬件负载均衡相比：

- 性能一般
- 功能没有硬件负载均衡那么强大
- 一般不具备防火墙和防 DDoS 攻击等安全功能

## 0.2. 负载均衡典型架构

**在架构设计中，基于上述方式的优缺点进行组合使用**，基本原则是：

- DNS负载均衡用于实现**地理**级别的负载均衡；
- 硬件负载均衡用于实现**集群**级别的负载均衡；
- 软件负载均衡用于实现**机器**级别的负载均衡。

![image](/images/3767c5f314bc966491ba0e556c0a63e4.png)

## 0.3. 负载均衡算法

负载均衡算法数量较多，且可根据业务特性进行定制开发，抛开细节差异，根据算法期望达到的目的，大体上可以分为下面几类。

1. 任务平分类：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。
2. 负载均衡类：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上说的“CPU负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力。
3. 性能最优类：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。
4. Hash 类：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。

### 0.3.1. 轮询

负载均衡系统收到请求后，按照顺序轮流分配到服务器上，无需关注服务器本身的状态。

**只要服务器在运行，运行状态是不关注的**。但如果服务器直接宕机了，或者服务器和负载均衡系统断连了，这时负载均衡系统是能够感知的，也需要做出相应的处理。

简单”是轮询算法的优点，也是它的缺点。

### 0.3.2. 加权轮询

负载均衡系统根据服务器**权重**（根据硬件配置进行静态配置）进行任务分配，如果采用动态的方式计算会更加契合业务，但复杂度也会更高。

加权轮询是轮询的一种特殊形式，其主要目的就是为了**解决不同服务器处理能力有差异的问题**。

加权轮询解决了轮询算法中无法根据服务器的配置差异进行任务分配的问题，但同样存在无法根据服务器的状态差异进行任务分配的问题。

### 0.3.3. 负载最低优先

负载均衡系统将任务分配给**当前负载最低**的服务器，这里的负载根据不同的任务类型和业务场景，可以用不同的指标来衡量。例如：

- LVS 这种 4 层网络负载均衡设备，可以以“**连接数**”来判断服务器的状态，服务器连接数越大，表明服务器压力越大。
- Nginx 这种 7 层网络负载系统，可以以“**HTTP 请求数**”来判断服务器状态（Nginx 内置的负载均衡算法不支持这种方式，需要进行扩展）。
- 自研负载均衡系统，可以根据业务特点来选择指标衡量系统压力。如果是 CPU 密集型，可以以“**CPU 负载**”来衡量系统压力；如果是 I/O 密集型，可以以“**I/O 负载**”来衡量系统压力。

负载最低优先的算法解决了轮询算法中无法感知服务器状态的问题，由此带来的代价是复杂度要增加很多。例如：

- **最少连接数优先**的算法：要求负载均衡系统统计每个服务器当前建立的连接，其应用场景**仅限于负载均衡接收的任何连接请求都会转发给服务器进行处理**，否则如果负载均衡系统和服务器之间是固定的连接池方式，就不适合采取这种算法。
- **CPU 负载最低优先**的算法：要求负载均衡系统以某种方式收集每个服务器的 CPU 负载，而且要确定是以 1 分钟的负载为标准，还是以 15 分钟的负载为标准，不存在 1 分钟肯定比 15 分钟要好或者差。**不同业务最优的时间间隔是不一样的**，时间间隔太短容易造成频繁波动，时间间隔太长又可能造成峰值来临时响应缓慢。

负载最低优先算法基本上能够比较完美地解决轮询算法的缺点，因为采用这种算法后，负载均衡系统需要感知服务器当前的运行状态。其代价是**复杂度**大幅上升。

> 负载最低优先算法如果本身没有设计好，或者不适合业务的运行特点，算法本身就可能成为性能的瓶颈，或者引发很多莫名其妙的问题。所以负载最低优先算法虽然效果看起来很美好，但实际上真正应用的场景反而没有轮询（包括加权轮询）那么多。

### 0.3.4. 性能最优类

- 负载最低优先类算法是站在**服务器**的角度来进行分配的，
- 性能最优优先类算法是站在**客户端**的角度来进行分配的，优先将任务分配给处理速度最快的服务器，达到最快响应客户端的目的。

性能最优优先类算法本质上也是**感知服务器的状态**，只是通过**响应时间**这个外部标准来衡量服务器状态而已。

因此性能最优优先类算法的**复杂度**都很高，主要体现在：

- 负载均衡系统需要收集和分析每个服务器每个任务的响应时间，在大量任务处理的场景下，这种收集和统计本身也会消耗较多的性能。
- 为了减少这种统计上的消耗，可以采取采样的方式来统计，即不统计所有任务的响应时间，而是抽样统计部分任务的响应时间来估算整体任务的响应时间。采样统计虽然能够减少性能消耗，但使得复杂度进一步上升，因为要确定合适的采样率，采样率太低会导致结果不准确，采样率太高会导致性能消耗较大，**找到合适的采样率也是一件复杂的事情**。
- 无论是全部统计还是采样统计，都需要选择合适的**周期**：是 10 秒内性能最优，还是 1 分钟内性能最优，还是 5 分钟内性能最优，需要根据实际业务进行判断和选择，这也是一件比较复杂的事情，甚至出现系统上线后需要不断地调优才能达到最优设计。

### 0.3.5. Hash类

负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上，这样做的目的主要是为了满足特定的业务需求。例如：

- 源地址 Hash：将来源于同一个源 IP 地址的任务分配给同一个服务器进行处理，适合于存在事务、会话的业务
- ID Hash：将某个 ID 标识的业务分配到同一个服务器中进行处理，这里的 ID 一般是临时性数据的 ID（如 session id）
